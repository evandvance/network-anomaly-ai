{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import auc, precision_recall_curve, accuracy_score, precision_score, recall_score\n",
    "import os\n",
    "import glob\n",
    "from helpers import trainer_factory \n",
    "\n",
    "\n",
    "def eval_model(model, X_test, y_test):\n",
    "    score = {}\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Convert -1 (anomaly) to 0 for consistency with your labels\n",
    "    predictions[predictions == -1] = 0\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
    "    score[\"auc\"] = auc(recall, precision)\n",
    "    score[\"precision\"] = precision_score(y_test, predictions)\n",
    "    score[\"recall\"] = recall_score(y_test, predictions)\n",
    "    score[\"accuracy\"] = accuracy_score(y_test, predictions)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/nima/Downloads/archive-2' \n",
    "\n",
    "\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)  \n",
    "    dataframes.append(df) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1:\n",
      "  Total Labels: 288602\n",
      "  BENIGN Labels: 288566\n",
      "  Anomalous Labels: 36\n",
      "------------------------------\n",
      "File 2:\n",
      "  Total Labels: 529918\n",
      "  BENIGN Labels: 529918\n",
      "  Anomalous Labels: 0\n",
      "------------------------------\n",
      "File 3:\n",
      "  Total Labels: 191033\n",
      "  BENIGN Labels: 189067\n",
      "  Anomalous Labels: 1966\n",
      "------------------------------\n",
      "File 4:\n",
      "  Total Labels: 286467\n",
      "  BENIGN Labels: 127537\n",
      "  Anomalous Labels: 158930\n",
      "------------------------------\n",
      "File 5:\n",
      "  Total Labels: 225745\n",
      "  BENIGN Labels: 97718\n",
      "  Anomalous Labels: 128027\n",
      "------------------------------\n",
      "File 6:\n",
      "  Total Labels: 445909\n",
      "  BENIGN Labels: 432074\n",
      "  Anomalous Labels: 13835\n",
      "------------------------------\n",
      "File 7:\n",
      "  Total Labels: 692703\n",
      "  BENIGN Labels: 440031\n",
      "  Anomalous Labels: 252672\n",
      "------------------------------\n",
      "File 8:\n",
      "  Total Labels: 170366\n",
      "  BENIGN Labels: 168186\n",
      "  Anomalous Labels: 2180\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(dataframes):\n",
    "    print(f\"File {i+1}:\")\n",
    "    # Count the total occurrences of each unique label value\n",
    "    label_counts = df[' Label'].value_counts()\n",
    "    # Get the total number of rows (total labels)\n",
    "    total_labels = df[' Label'].count()\n",
    "\n",
    "    benign_count = label_counts.get('BENIGN', 0)  \n",
    "    print(f\"  Total Labels: {total_labels}\")\n",
    "    print(f\"  BENIGN Labels: {benign_count}\")\n",
    "    print(f\"  Anomalous Labels: {total_labels - benign_count}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "combined_df.columns = combined_df.columns.str.strip()\n",
    "\n",
    "\n",
    "X_combined = combined_df.drop(columns=['Label'])  # Drop the 'Label' column\n",
    "y_combined = combined_df['Label'].apply(lambda x: 'BENIGN' if x == 'BENIGN' else 'MALICIOUS')  # Set the label to 0 for 'BENIGN' and 1 for 'MALICIOUS'\n",
    " \n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder() # Initialize the label encoder\n",
    "y_encoded = label_encoder.fit_transform(y_combined) # Encode the labels to 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure X_combined and y_encoded are DataFrames\n",
    "X_combined = pd.DataFrame(X_combined)\n",
    "y_encoded = pd.DataFrame(y_encoded)\n",
    "\n",
    "# Replace infinity values and drop NaNs\n",
    "X_combined.replace([float('inf'), float('-inf')], float('nan'), inplace=True)\n",
    "X_combined.dropna(inplace=True)\n",
    "\n",
    "# Align y_encoded with the index of X_combined\n",
    "y_encoded = y_encoded.loc[X_combined.index]\n",
    "\n",
    "# Reset index for DataFrames\n",
    "X_combined.reset_index(drop=True, inplace=True)\n",
    "y_encoded.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found: {'contamination': 'auto', 'max_features': 1.0, 'max_samples': 128, 'n_estimators': 100}\n",
      "Evaluation Metrics: {'auc': 0.44604828643517214, 'precision': 0.1551950319079267, 'recall': 0.6721003471352396, 'accuracy': 0.21217130854208807}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_samples': [128, 256, 'auto'],\n",
    "    'contamination': ['auto', 0.01, 0.05],\n",
    "    'max_features': [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    IsolationForest(random_state=0),\n",
    "    param_grid,\n",
    "    scoring='roc_auc',  \n",
    "    cv=3,                \n",
    "    n_jobs=-1            \n",
    ")\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters Found:\", best_params)\n",
    "\n",
    "\n",
    "isolation_trainer = trainer_factory(IsolationForest, X_train, y_train)\n",
    "isoforest, _ = isolation_trainer(**best_params)\n",
    "\n",
    "\n",
    "score = eval_model(isoforest, X_test, y_test)\n",
    "print(\"Evaluation Metrics:\", score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIS377",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
